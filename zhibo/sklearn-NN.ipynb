{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yangzhibo5947/anaconda3/envs/tensorflow/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2851\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv('voice.csv')\n",
    "label = all_data.pop('label')\n",
    "\n",
    "all_data = all_data.values\n",
    "\n",
    "label.replace(['male','female'], [1, 0], inplace = True)\n",
    "label = label.values\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(all_data, label, test_size = 0.1)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = np.array(train_data, dtype = 'float32'), np.array(test_data, dtype = 'float32'),np.array(train_labels, dtype = 'float32'),np.array(test_labels, dtype = 'float32')\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler  \n",
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(train_data)  \n",
    "train_data = scaler.transform(train_data )  \n",
    "# apply same transformation to test data\n",
    "test_data = scaler.transform(test_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 30, 100), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=10000, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=2, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(solver='adam', alpha=1e-5,\n",
    "                  hidden_layer_sizes=(100, 30, 100), random_state=2, max_iter=10000, warm_start=True)\n",
    "\n",
    "mlp.fit(train_data,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  0.  1.  0.  0.  0.  1.  1.  0.  0.  1.  1.  0.  0.  1.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.\n",
      "  0.  1.  0.  0.  0.  0.  1.  1.  0.  0.  1.  1.  1.  1.  1.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  1.  1.  0.  1.  0.  1.  0.  1.  0.  1.  1.  0.  0.\n",
      "  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.  1.  0.  0.  0.  0.  1.  1.  1.\n",
      "  1.  0.  1.  1.  0.  1.  1.  0.  0.  0.  0.  1.  0.  1.  1.  1.  0.  1.\n",
      "  1.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  1.  0.\n",
      "  1.  0.  0.  1.  1.  1.  0.  1.  1.  0.  0.  0.  1.  0.  1.  0.  1.  1.\n",
      "  1.  1.  0.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1.  1.  1.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.  1.\n",
      "  1.  0.  1.  1.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  1.  1.  1.  0.\n",
      "  1.  1.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  1.  1.  0.  1.  1.  1.\n",
      "  0.  1.  0.  1.  0.  1.  0.  1.  1.  1.  0.  0.  0.  0.  0.  1.  0.  1.\n",
      "  1.  0.  0.  1.  1.  0.  0.  1.  0.  1.  0.  1.  1.  0.  1.  0.  0.  0.\n",
      "  1.  0.  1.  1.  1.  0.  1.  0.  1.  1.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  1.  1.  0.  0.  1.  0.  1.  1.  1.  1.  0.  0.  1.  0.  1.  0.  0.  0.\n",
      "  1.  1.  1.  1.  0.  1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  0.  1.  1.\n",
      "  0.  1.  1.  0.  1.  1.  0.  0.  1.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "y_test = mlp.predict(test_data)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted number of female 166\n",
      "predicted number of male 150\n",
      "total number of train data: 316\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "for i in range(0,316):\n",
    "    #if y_test[i] < 0.4:\n",
    "     if  (y_test[i] == 0):\n",
    "       count_0 += 1\n",
    "     else:\n",
    "       count_1 += 1\n",
    "print(\"predicted number of female\", count_0)\n",
    "print(\"predicted number of male\", count_1)\n",
    "print(\"total number of train data:\",count_0 + count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correct prediction 308\n",
      "Number of wrong prediction 8\n"
     ]
    }
   ],
   "source": [
    "correct_predic = 0\n",
    "wrong_predic = 0\n",
    "for i in range(0,316):\n",
    "    if test_labels[i] == y_test[i]:\n",
    "       correct_predic += 1\n",
    "    else:\n",
    "       wrong_predic += 1\n",
    "    \n",
    "print(\"Number of correct prediction\", correct_predic)\n",
    "print(\"Number of wrong prediction\", wrong_predic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct rate is:  0.9746835443037974\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct rate is: \", correct_predic/(wrong_predic + correct_predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow]",
   "language": "python",
   "name": "Python [tensorflow]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
